{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "first-module.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNfIQrcG9NA7jySmuIhqxBV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fouyos/ml-newbs/blob/main/first_module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LCoUg4vdjAN",
        "colab_type": "text"
      },
      "source": [
        "Melakukan Import library pandas dan memberikan alias ‘pd’ untuk library tersebut. Memberikan alias ‘pd’ terhadap library pandas adalah praktek yang umum dilakukan para pengembang ML."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRUXwZntdJIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmDx7GmYdrin",
        "colab_type": "text"
      },
      "source": [
        "Colab memiliki direktori yang menyimpan berkas-berkas umum yang dapat dipakai untuk berbagai keperluan. Berkas-berkas bawaan tersebut disimpan dalam sebuah direktori bernama ‘sample_data’."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvI9oXj1dhD8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "5091bd5a-9b2b-4712-e3d2-d6cb416580c7"
      },
      "source": [
        "import os\n",
        "os.listdir('sample_data')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['anscombe.json',\n",
              " 'README.md',\n",
              " 'mnist_train_small.csv',\n",
              " 'mnist_test.csv',\n",
              " 'california_housing_test.csv',\n",
              " 'california_housing_train.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AerJUB-xdzm6",
        "colab_type": "text"
      },
      "source": [
        "Pada latihan ini kita akan mencoba melakukan konversi dari berkas ‘california_housing_train.csv’ yang merupakan bawaan dari Colab. Untuk mengubah berkas csv menjadi dataframe, kita menggunakan fungsi ‘read_csv’ pada library pandas kemudian menyimpannya pada sebuah variabel yaitu df."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Y3wpueGd15g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "8eecf0ee-0b11-4031-d22d-63e83c90cff7"
      },
      "source": [
        "df = pd.read_csv('sample_data/california_housing_train.csv')\n",
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "      <td>66900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "      <td>80100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "      <td>85700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "      <td>73400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "      <td>65500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   longitude  latitude  ...  median_income  median_house_value\n",
              "0    -114.31     34.19  ...         1.4936             66900.0\n",
              "1    -114.47     34.40  ...         1.8200             80100.0\n",
              "2    -114.56     33.69  ...         1.6509             85700.0\n",
              "3    -114.57     33.64  ...         3.1917             73400.0\n",
              "4    -114.57     33.57  ...         1.9250             65500.0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWrWg1W7g2K7",
        "colab_type": "text"
      },
      "source": [
        "Salah satu contoh dari normalization adalah min-max scaling di mana nilai-nilai dipetakan ke dalam skala 0 sampai 1. SKLearn menyediakan library untuk normalization\n",
        "\n",
        "Pada Colab kita Import library MinMaxScaler dan masukkan data dari tabel sebelumnya."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0TfhtzYg6DV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "data = [[12000000, 33], [35000000, 45], [4000000, 23], [6500000, 26], [9000000, 29]]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LGo4Pj5hGHG",
        "colab_type": "text"
      },
      "source": [
        "Pada cell selanjutnya kita buat object scaler dan panggil fungsi fit() pada data. Fungsi fit adalah fungsi untuk menghitung nilai minimum dan maksimum pada tiap kolom."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aN5gJsh8hI6W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9b4da4ce-a524-4d3a-ade0-912bcf51004d"
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaler.fit(data)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MinMaxScaler(copy=True, feature_range=(0, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQu0QXPmhQMN",
        "colab_type": "text"
      },
      "source": [
        "Terakhir kita panggil fungsi transform yang akan mengaplikasikan scaler pada data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkh7n_LHhNWG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6b3ecb34-6045-4664-fd42-db102d9faf4e"
      },
      "source": [
        "print(scaler.transform(data))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.25806452 0.45454545]\n",
            " [1.         1.        ]\n",
            " [0.         0.        ]\n",
            " [0.08064516 0.13636364]\n",
            " [0.16129032 0.27272727]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9eDdM4UhRfQ",
        "colab_type": "text"
      },
      "source": [
        "Pada colab di cell pertama, kita akan mengimport library preprocessing dari scikit learn lalu membuat data dummy sesuai dengan tabel di atas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yxhDUaLh8Ye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "data = [[12000000, 33], [35000000, 45], [4000000, 23], [6500000, 26], [9000000, 29]]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pr9AkJtIh_jL",
        "colab_type": "text"
      },
      "source": [
        "Selanjutnya kita buat object scaler dan panggil fungsi fit dari scaler pada data. Fungsi fit memiliki fungsi untuk menghitung rata-rata dan deviasi standar dari setiap kolom atribut untuk kemudian dipakai pada fungsi transform."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc-r3Wt4iBKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = preprocessing.StandardScaler().fit(data)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HR2xm3BxiDr_",
        "colab_type": "text"
      },
      "source": [
        "Terakhir, kita panggil fungsi transform untuk mengaplikasikan standard scaler pada data. Untuk melihat hasil dari standard scaler kita tinggal memanggil objek scaler yang telah kita buat sebelumnya. Kodenya sebagai berikut."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dulM_iziFWY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "9a58b3af-cd24-4b1e-9930-af7c11d43660"
      },
      "source": [
        "data = scaler.transform(data)\n",
        "data"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.11638732,  0.23521877],\n",
              "       [ 1.94277296,  1.80334389],\n",
              "       [-0.83261698, -1.07155217],\n",
              "       [-0.60879521, -0.67952089],\n",
              "       [-0.38497344, -0.28748961]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJ50SwyekHxx",
        "colab_type": "text"
      },
      "source": [
        "Library Scikit Learn menyediakan fungsi untuk membagi dataset menjadi train set (data training) dan test set (data testing).\n",
        "\n",
        "Pada Colab kita import library yang dibutuhkan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H56nWSvkKIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UEtdkqLkMDL",
        "colab_type": "text"
      },
      "source": [
        "Library sklearn menyediakan dataset iris yakni sebuah dataset yang umum digunakan untuk masalah klasifikasi. Dataset ini memiliki jumlah 150 sampel. Untuk mendapatkan dataset, kita bisa menulis kode berikut pada cell baru."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRR5tGdmkORJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris = datasets.load_iris()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMOlxF3nkSni",
        "colab_type": "text"
      },
      "source": [
        "Dataset iris dari library sklearn belum dapat langsung dipakai oleh sebuah model ML. Sesuai dengan yang telah dibahas pada modul terdahulu, kita harus memisahkan antara atribut dan label pada dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oa_bSH7okVzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=iris.data\n",
        "y=iris.target"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT214B82kaku",
        "colab_type": "text"
      },
      "source": [
        "Untuk membuat train set dan test set kita tinggal memanggil fungsi train_test_split. Train_test_split memiliki parameter x yaitu atribut dari dataset, y yaitu target dari dataset, dan test_size yaitu persentase dari test \n",
        "\n",
        "set dari dataset utuh. Train_test_split mengembalikan 4 nilai yaitu, atribut dari train set, atribut  dari test set, target dari train set, dan target dari test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWp9kMDokiIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UA5apdOzkv8J",
        "colab_type": "text"
      },
      "source": [
        "Ketika kita print panjang dari x_test, kita bisa melihat bahwa panjang dari atribut test set adalah 30 sampel, sesuai dengan parameter yang kita masukkan pada fungsi train_test_split yaitu 0.2 atau 20% dari 150 sampel. Kode untuk print panjang dari x_test seperti di bawah ini"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAvxNEJ6kx5K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36423da0-20d8-45ec-d3e6-cf4f1af3e143"
      },
      "source": [
        "len(x_test)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FqazfyZmdfu",
        "colab_type": "text"
      },
      "source": [
        "Library SKLearn menyediakan fungsi cross_val_score untuk menghitung hasil dari cross validation sebuah classifier bawaan sklearn. Pada coding practice kali ini kita akan menggunakan cross_validation_score pada classifier decision_tree. Dataset yang digunakan adalah dataset iris."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy1e5dQumgCt",
        "colab_type": "text"
      },
      "source": [
        "Pada Colab kita import semua library yang dibutuhkan di cell pertama. Dataset yang akan kita gunakan adalah dataset iris yang dipakai pada submodul sebelumnya."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1uLmRXXmht6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import  tree\n",
        "iris = datasets.load_iris()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ST2fmxkhmj1w",
        "colab_type": "text"
      },
      "source": [
        "Kemudian kita bagi antara atribut dan label pada dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UZ6btu_mlL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=iris.data\n",
        "y=iris.target"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBtBAzWUmneI",
        "colab_type": "text"
      },
      "source": [
        "Kita akan membuat model machine learning pertama kita yaitu decision tree, menggunakan library scikit learn. Model machine learning juga sering disebut sebagai classifier. Lebih lanjut, variabel clf adalah singkatan dari classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6n5kfrOQmpl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = tree.DecisionTreeClassifier()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX3MpopGmrlA",
        "colab_type": "text"
      },
      "source": [
        "Setelah dataset dan model siap, kita bisa menggunakan cross validation untuk mengevaluasi performa dari model machine learning. Fungsi cross_val_score seperti di bawah menerima 4 parameter yaitu, ‘clf’ yang merupakan model machine learning, ‘X’ yang merupakan atribut dari dataset, ‘y’ yang merupakan label dari dataset, dan ‘cv’ yang merupakan jumlah fold yang akan dipakai pada cross validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZaZ5SIXmwso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores = cross_val_score(clf, x, y, cv=4)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYuFT3NTm-s2",
        "colab_type": "text"
      },
      "source": [
        "Cross_val_score mengembalikan nilai berupa larik atau array yang terdiri dari akurasi pengujian setiap fold dari dataset. Untuk mencetak dan mengetahui hasilnya, tambahkan kode scores di bawah kode sebelumnya. Tampilannya seperti gambar di bawah ini."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9egVh53inCpw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8fc99f42-d175-41d1-8ff8-d6d73535eca9"
      },
      "source": [
        "scores"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.97368421, 0.94736842, 0.94594595, 0.97297297])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    }
  ]
}